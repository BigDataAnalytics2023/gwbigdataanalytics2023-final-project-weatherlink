{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jOsfGNHHFPc"
      },
      "source": [
        "Authentication - you will need to upload the service account key json file when prompted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ProjPD-QHD3j",
        "outputId": "134b34ca-148c-4e52-ff04-e16b89aee49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload the private key for your service account.\n",
            "\n",
            "See the guide at https://cloud.google.com/iam/docs/creating-managing-service-account-keys#iam-service-account-keys-create-console for help.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e09a41b3-dc5a-4a3f-935b-7e0a0a9f9e5a\" name=\"files[]\"  disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e09a41b3-dc5a-4a3f-935b-7e0a0a9f9e5a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": [
              "48219e68-0f1f-4a14-b36c-4df060984885"
            ]
          },
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0302f90c5dfb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_service_account\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_service_account\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;31m# TODO(b/226659795): Offer programmatic option, https://cloud.google.com/iam/docs/creating-managing-service-account-keys#iam-service-account-keys-create-gcloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0muploaded_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madc_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muploaded_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m           \u001b[0;31m# Upload was cancelled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0mwere\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0muploaded_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muploaded_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_service_account()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I2CIx83VofW",
        "outputId": "d7c237ee-c22b-4489-a7fa-9696dac792f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table name bigquery-public-data.nhtsa_traffic_fatalities. accident_2015 has 90 cols\n",
            "Table name bigquery-public-data.nhtsa_traffic_fatalities. accident_2016 has 92 cols\n",
            "Table name bigquery-public-data.nhtsa_traffic_fatalities. accident_2017 has 92 cols\n",
            "Table name bigquery-public-data.nhtsa_traffic_fatalities. accident_2018 has 92 cols\n",
            "Table name bigquery-public-data.nhtsa_traffic_fatalities. accident_2019 has 92 cols\n",
            "Table name bigquery-public-data.nhtsa_traffic_fatalities. accident_2020 has 82 cols\n",
            "404 GET https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/nhtsa_traffic_fatalities/tables/%20accident_2021?prettyPrint=false: Not found: Table bigquery-public-data:nhtsa_traffic_fatalities. accident_2021\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2021 not found\n",
            "404 GET https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/nhtsa_traffic_fatalities/tables/%20accident_2022?prettyPrint=false: Not found: Table bigquery-public-data:nhtsa_traffic_fatalities. accident_2022\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2022 not found\n",
            "404 GET https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/nhtsa_traffic_fatalities/tables/%20accident_2023?prettyPrint=false: Not found: Table bigquery-public-data:nhtsa_traffic_fatalities. accident_2023\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2023 not found\n",
            "404 GET https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/nhtsa_traffic_fatalities/tables/%20accident_2024?prettyPrint=false: Not found: Table bigquery-public-data:nhtsa_traffic_fatalities. accident_2024\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2024 not found\n",
            "Unique columns in bigquery-public-data.nhtsa_traffic_fatalities. accident_2015: set()\n",
            "Unique columns in bigquery-public-data.nhtsa_traffic_fatalities. accident_2016: {'county_name', 'city_name'}\n",
            "Unique columns in bigquery-public-data.nhtsa_traffic_fatalities. accident_2017: {'county_name', 'city_name'}\n",
            "Unique columns in bigquery-public-data.nhtsa_traffic_fatalities. accident_2018: {'county_name', 'city_name'}\n",
            "Unique columns in bigquery-public-data.nhtsa_traffic_fatalities. accident_2019: {'county_name', 'city_name'}\n",
            "Unique columns in bigquery-public-data.nhtsa_traffic_fatalities. accident_2020: {'county_name', 'city_name'}\n",
            "'bigquery-public-data.nhtsa_traffic_fatalities. accident_2021'\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2021 not found\n",
            "'bigquery-public-data.nhtsa_traffic_fatalities. accident_2022'\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2022 not found\n",
            "'bigquery-public-data.nhtsa_traffic_fatalities. accident_2023'\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2023 not found\n",
            "'bigquery-public-data.nhtsa_traffic_fatalities. accident_2024'\n",
            "Table bigquery-public-data.nhtsa_traffic_fatalities. accident_2024 not found\n",
            "\n",
            "Master DataFrame:\n",
            "        number_of_persons_in_motor_vehicles_in_transport_mvit milepoint_name  \\\n",
            "0                                                       1                489   \n",
            "1                                                       2                680   \n",
            "2                                                       1                110   \n",
            "3                                                       3                639   \n",
            "4                                                       2                760   \n",
            "...                                                   ...                ...   \n",
            "203460                                                  1                 74   \n",
            "203461                                                  1       Not Reported   \n",
            "203462                                                  1                 27   \n",
            "203463                                                  1                105   \n",
            "203464                                                  1       Not Reported   \n",
            "\n",
            "        number_of_forms_submitted_for_persons_in_motor_vehicles  \\\n",
            "0                                                       1         \n",
            "1                                                       2         \n",
            "2                                                       1         \n",
            "3                                                       3         \n",
            "4                                                       2         \n",
            "...                                                   ...         \n",
            "203460                                                  1         \n",
            "203461                                                  1         \n",
            "203462                                                  1         \n",
            "203463                                                  1         \n",
            "203464                                                  1         \n",
            "\n",
            "              ownership_name  \\\n",
            "0       State Highway Agency   \n",
            "1       State Highway Agency   \n",
            "2       State Highway Agency   \n",
            "3       State Highway Agency   \n",
            "4       State Highway Agency   \n",
            "...                      ...   \n",
            "203460          Not Reported   \n",
            "203461          Not Reported   \n",
            "203462          Not Reported   \n",
            "203463  State Highway Agency   \n",
            "203464          Not Reported   \n",
            "\n",
            "       relation_to_junction_within_interchange_area_name  hour_of_crash  \\\n",
            "0                                                     No             23   \n",
            "1                                                     No              4   \n",
            "2                                                     No              8   \n",
            "3                                                    Yes             18   \n",
            "4                                                     No             20   \n",
            "...                                                  ...            ...   \n",
            "203460                                                No             13   \n",
            "203461                                                No             22   \n",
            "203462                                                No             21   \n",
            "203463                                               Yes              4   \n",
            "203464                                                No              4   \n",
            "\n",
            "       school_bus_related_name functional_system_name  school_bus_related  \\\n",
            "0                           No             Interstate                   0   \n",
            "1                           No             Interstate                   0   \n",
            "2                           No             Interstate                   0   \n",
            "3                           No             Interstate                   0   \n",
            "4                           No             Interstate                   0   \n",
            "...                        ...                    ...                 ...   \n",
            "203460                     NaN        Major Collector                <NA>   \n",
            "203461                     NaN        Major Collector                <NA>   \n",
            "203462                     NaN        Major Collector                <NA>   \n",
            "203463                     NaN        Major Collector                <NA>   \n",
            "203464                     NaN        Major Collector                <NA>   \n",
            "\n",
            "        number_of_parked_working_vehicles  ...  atmospheric_conditions_name  \\\n",
            "0                                       0  ...                       Cloudy   \n",
            "1                                       0  ...                         Rain   \n",
            "2                                       0  ...                        Clear   \n",
            "3                                       0  ...                        Clear   \n",
            "4                                       0  ...                        Clear   \n",
            "...                                   ...  ...                          ...   \n",
            "203460                                  0  ...                          NaN   \n",
            "203461                                  0  ...                          NaN   \n",
            "203462                                  0  ...                          NaN   \n",
            "203463                                  0  ...                          NaN   \n",
            "203464                                  0  ...                          NaN   \n",
            "\n",
            "       atmospheric_conditions_2 related_factors_crash_level_3_name  work_zone  \\\n",
            "0                             0                               None          0   \n",
            "1                             0                               None          0   \n",
            "2                             0                               None          0   \n",
            "3                             0                               None          0   \n",
            "4                             0                               None          0   \n",
            "...                         ...                                ...        ...   \n",
            "203460                        0                                NaN          0   \n",
            "203461                        0                                NaN          0   \n",
            "203462                        0                                NaN          0   \n",
            "203463                        0                                NaN          0   \n",
            "203464                        0                                NaN          0   \n",
            "\n",
            "       minute_of_crash  number_of_fatalities ownership  manner_of_collision  \\\n",
            "0                   28                     1         1                    0   \n",
            "1                   20                     1         1                    0   \n",
            "2                   11                     1         1                    0   \n",
            "3                   15                     1         1                    0   \n",
            "4                    0                     1         1                    0   \n",
            "...                ...                   ...       ...                  ...   \n",
            "203460              30                     1        98                    0   \n",
            "203461               8                     1        98                    0   \n",
            "203462              11                     1        98                    0   \n",
            "203463              15                     1         1                    0   \n",
            "203464              52                     1        98                    0   \n",
            "\n",
            "        year  geoid  \n",
            "0       2015  01127  \n",
            "1       2015  01053  \n",
            "2       2015  01101  \n",
            "3       2015  01053  \n",
            "4       2015  01017  \n",
            "...      ...    ...  \n",
            "203460  2020  48201  \n",
            "203461  2020  48375  \n",
            "203462  2020  48113  \n",
            "203463  2020  48201  \n",
            "203464  2020  48303  \n",
            "\n",
            "[203465 rows x 92 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "\n",
        "project_name='weatherlink-404323'\n",
        "client = bigquery.Client()\n",
        "\n",
        "year_start = 2015\n",
        "year_stop = 2025\n",
        "\n",
        "# Initialize a dictionary to store the schema for each table\n",
        "table_schemas = {}\n",
        "\n",
        "# Initialize a set to store common columns\n",
        "common_columns_set = None\n",
        "\n",
        "# Initialize a dictionary to store unique columns for each table\n",
        "unique_columns_dict = {}\n",
        "\n",
        "# Initialize a list to store DataFrames for each year\n",
        "dfs = []\n",
        "\n",
        "for i in range(year_start, year_stop):\n",
        "    table_name = f\"bigquery-public-data.nhtsa_traffic_fatalities. accident_{i}\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Fetch the schema (column information) for each table\n",
        "        if table_name not in table_schemas:\n",
        "            table = client.get_table(table_name)\n",
        "            table_schemas[table_name] = set([field.name for field in table.schema])\n",
        "\n",
        "        # If this is the first DataFrame, initialize the set with its columns\n",
        "        if common_columns_set is None:\n",
        "            common_columns_set = set(table_schemas[table_name])\n",
        "        else:\n",
        "            # Update the set to include only columns present in both DataFrames\n",
        "            common_columns_set.intersection_update(table_schemas[table_name])\n",
        "\n",
        "        # Update the set to include only columns not present in other DataFrames\n",
        "        unique_columns_dict[table_name] = table_schemas[table_name].difference(common_columns_set)\n",
        "\n",
        "        print(f\"Table name {table_name} has {len(table_schemas[table_name])} cols\")\n",
        "\n",
        "        # Fetch the data and add it to a DataFrame\n",
        "        query = f\"SELECT * FROM `{table_name}`\"\n",
        "        df = client.query(query).to_dataframe()\n",
        "\n",
        "        # Add the 'year' column to the DataFrame\n",
        "        df['year'] = i\n",
        "\n",
        "        # Calculate the FIPS code\n",
        "        df['county'] = df['county'].astype(str)\n",
        "        df['county'] = df['county'].str.zfill(3)\n",
        "        df['state_number'] = df['state_number'].astype(str)\n",
        "        df['state_number'] = df['state_number'].str.zfill(2)\n",
        "\n",
        "        df['geoid'] = df['state_number'] + df['county']\n",
        "\n",
        "        # Keep only the common columns\n",
        "        df = df[list(common_columns_set) + ['year'] + ['geoid']]\n",
        "\n",
        "        # Append the DataFrame to the list\n",
        "        dfs.append(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f\"Table {table_name} not found\")\n",
        "\n",
        "# Print unique columns for each table\n",
        "for i in range(year_start, year_stop):\n",
        "    table_name = f\"bigquery-public-data.nhtsa_traffic_fatalities. accident_{i}\"\n",
        "    try:\n",
        "        print(f\"Unique columns in {table_name}: {unique_columns_dict[table_name]}\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f\"Table {table_name} not found\")\n",
        "\n",
        "# Concatenate all DataFrames into a master DataFrame\n",
        "master_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Print the master DataFrame\n",
        "print(\"\\nMaster DataFrame:\")\n",
        "print(master_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBu3XBged4Kj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDSRxhR1g6Xy"
      },
      "source": [
        "\n",
        "we are going to upload this dataframe to Google Big Query in our 'Data Warehouse', and then select a number of columns to compare for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtM5JBqXkMDS",
        "outputId": "9889e658-5e40-4603-dc0b-d2ac408862c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_gbq in /usr/local/lib/python3.10/dist-packages (0.17.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (67.7.2)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.5.3)\n",
            "Requirement already satisfied: pyarrow<10.0dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (9.0.0)\n",
            "Requirement already satisfied: pydata-google-auth in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.8.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (2.11.1)\n",
            "Requirement already satisfied: google-auth>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (1.0.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pandas_gbq) (2.22.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from db-dtypes<2.0.0,>=0.3.1->pandas_gbq) (23.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.61.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.25.0->pandas_gbq) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.25.0->pandas_gbq) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.25.0->pandas_gbq) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.25.0->pandas_gbq) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.0.1->pandas_gbq) (1.3.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.59.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.22.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.6.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->pandas_gbq) (2023.3.post1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (1.48.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=1.27.2->pandas_gbq) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.25.0->pandas_gbq) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->pandas_gbq) (2023.7.22)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.0.1->pandas_gbq) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas_gbq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3r_phP4d9NE",
        "outputId": "beda4d77-7464-4a67-c301-860e6d7175ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-e6e8c136e94d>:16: DtypeWarning: Columns (6,11,57,82,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  new_df = pd.read_csv(temp_csv_string_IO, sep=\";\")\n",
            "100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n"
          ]
        }
      ],
      "source": [
        "from pandas_gbq import to_gbq\n",
        "from pandas_gbq.schema import generate_bq_schema\n",
        "from io import StringIO\n",
        "\n",
        "client = bigquery.Client()\n",
        "\n",
        "project_id='weatherlink-404323'\n",
        "dataset_id = 'weatherlink_master'\n",
        "table_id = 'accident_master'\n",
        "\n",
        "# This is a weird work around to get the dataframe acceptable for upload\n",
        "# temporarily store the dataframe as a csv in a string variable\n",
        "temp_csv_string = master_df.to_csv(sep=\";\", index=False)\n",
        "temp_csv_string_IO = StringIO(temp_csv_string)\n",
        "# create new dataframe from string variable\n",
        "new_df = pd.read_csv(temp_csv_string_IO, sep=\";\")\n",
        "\n",
        "to_gbq(new_df, f\"{dataset_id}.{table_id}\", project_id=project_id, if_exists='replace')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNQrUO2jqDzq"
      },
      "source": [
        "Lets test by querying our new master table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3QsV5bDqF6y",
        "outputId": "74d40566-f9c4-4564-ccec-0c7ce87e4046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QueryJob<project=weatherlink-404323, location=US, id=a28bd2f3-62ce-40c4-9140-54a308978395>\n"
          ]
        }
      ],
      "source": [
        "sql = f\" SELECT COUNT(*) FROM {project_id}.{dataset_id}.{table_id}\"\n",
        "\n",
        "result = client.query(sql)\n",
        "\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}